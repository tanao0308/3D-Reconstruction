{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinect-Fusion算法流程重点解析\n",
    "## 本周工作\n",
    "#### 本周阅读了开源项目[tsdf-fusion-python](https://github.com/andyzeng/tsdf-fusion-python)的代码并添加了ICP算法\n",
    "## 发表流程\n",
    "### 1. 项目代码结构讲解\n",
    "### 2. TSDF算法讲解\n",
    "### 3. ICP算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. 项目代码结构讲解\n",
    "### 项目框架\n",
    "项目代码框架图如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "├── fusion.py\n",
      "├── \u001b[01;34micp\u001b[0m\n",
      "│   ├── depth2cloud.py\n",
      "│   ├── icp.py\n",
      "│   ├── main.py\n",
      "│   └── \u001b[01;32mrun.sh\u001b[0m\n",
      "├── \u001b[01;32mmain.ipynb\u001b[0m\n",
      "├── main.py\n",
      "├── mesh.ply\n",
      "├── \u001b[01;32mrun.sh\u001b[0m\n",
      "└── \u001b[01;32mrun_jupyter.sh\u001b[0m\n",
      "\n",
      "2 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "!tree -I \"myenv|stair|*.jpg|*.txt|*.png|*.pyc|__*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data文件夹存放相机内参，1000张深度图和1000张相机位姿\n",
    "- main.py文件为算法主流程\n",
    "- fusion.py文件包含tsdf体素对象类和刚性变换等函数\n",
    "- icp文件夹为扩充的icp算法部分，使算法可以在没有相机位姿的情况下运行\n",
    "- mesh.ply为生成的三角形网格文件\n",
    "- run.sh为项目运行脚本\n",
    "\n",
    "\n",
    "\n",
    "### 项目主体流程\n",
    "- 估计体素体积边界（Voxel Volume Bounds）：\n",
    "    - 读取深度图像和相机位姿，利用相机视锥体计算体素边界。\n",
    "\n",
    "- 初始化体素体积：\n",
    "    - 使用体素体积边界和给定的体素大小（0.02米），初始化 TSDF 体素对象。\n",
    "\n",
    "- 融合 TSDF：\n",
    "    - 对每一帧进行 TSDF 融合，将深度图像与相机内参、相机位姿传递给 integrate 函数。\n",
    "\n",
    "- 保存网格：\n",
    "    - 将网格数据保存到mesh.ply文件\n",
    "\n",
    "项目用到numba库进行并行加速，skimage.measure库进行网格生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 100000000.0\n"
     ]
    }
   ],
   "source": [
    "# numba示例代码\n",
    "from numba import njit, prange\n",
    "import numpy as np\n",
    "\n",
    "@njit(parallel=True)\n",
    "def parallel_sum(arr):\n",
    "    total = 0.0\n",
    "    for i in prange(arr.shape[0]):\n",
    "        total += arr[i]\n",
    "    return total\n",
    "\n",
    "# 示例数据\n",
    "data = np.ones(100000000)\n",
    "\n",
    "# 调用并输出结果\n",
    "result = parallel_sum(data)\n",
    "print(\"Sum:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. TSDF算法讲解\n",
    "- TSDF算法的主体是融合(integrate)过程\n",
    "- fusion.py下的TSDFVolume类实现了方法：\n",
    "    - 体素网格坐标转换为世界坐标\n",
    "    - 相机坐标转换为像素坐标\n",
    "    - 加权融合tsdf值\n",
    "    - 利用体素tsdf值生成三角形网格数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 函数：体素网格坐标转换为世界坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vox2world(vol_origin, vox_coords, vox_size):\n",
    "    # 将体素网格坐标转换为世界坐标。\n",
    "    vol_origin = vol_origin.astype(np.float32)\n",
    "    vox_coords = vox_coords.astype(np.float32)\n",
    "    cam_pts = np.empty_like(vox_coords, dtype=np.float32)\n",
    "\n",
    "    # 使用并行循环将每个体素网格坐标转换为世界坐标\n",
    "    for i in prange(vox_coords.shape[0]):\n",
    "        for j in range(3):\n",
    "            cam_pts[i, j] = vol_origin[j] + (vox_size * vox_coords[i, j])\n",
    "    return cam_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 函数：相机坐标转换为像素坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[233, 367],\n",
       "       [267, 383],\n",
       "       [278, 389]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cam2pix(cam_pts, intr):\n",
    "    # 将相机坐标转换为像素坐标。\n",
    "    intr = intr.astype(np.float32)\n",
    "    fx, fy = intr[0, 0], intr[1, 1]\n",
    "    cx, cy = intr[0, 2], intr[1, 2]\n",
    "    pix = np.empty((cam_pts.shape[0], 2), dtype=np.int64)\n",
    "    for i in prange(cam_pts.shape[0]):\n",
    "        pix[i, 0] = int(np.round((cam_pts[i, 0] * fx / cam_pts[i, 2]) + cx))\n",
    "        pix[i, 1] = int(np.round((cam_pts[i, 1] * fy / cam_pts[i, 2]) + cy))\n",
    "    return pix\n",
    "\n",
    "cam_pts = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "intr = np.array([[100, 0, 200], [0, 100, 300], [0, 0, 1]])\n",
    "cam2pix(cam_pts, intr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 函数：加权融合tsdf值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.55 , 0.8  , 0.975], dtype=float32),\n",
       " array([2., 3., 4.], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def integratetsdf(tsdfvol, dist, w_old, obs_weight):\n",
    "    # 融合TSDF值\n",
    "    tsdfvol_int = np.empty_like(tsdfvol, dtype=np.float32)\n",
    "    w_new = np.empty_like(w_old, dtype=np.float32)\n",
    "    for i in prange(len(tsdfvol)):\n",
    "        w_new[i] = w_old[i] + obs_weight\n",
    "        tsdfvol_int[i] = (w_old[i] * tsdfvol[i] + obs_weight * dist[i]) / w_new[i]\n",
    "    return tsdfvol_int, w_new\n",
    "\n",
    "tsdfvol = np.array([0.1, 0.2, 0.3])\n",
    "dist = np.array([1.0, 2.0, 3.0])\n",
    "w_old = np.array([1.0,2.0,3.0])\n",
    "obs_weight = 1.0\n",
    "integratetsdf(tsdfvol, dist, w_old, obs_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数：对深度图进行一次迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n将一个深度图像帧集成到 TSDF 体积中。\\n\\n参数:\\n    depth_im (ndarray): 深度图像，形状为 (H, W)。\\n    cam_intr (ndarray): 相机内参矩阵，形状为 (3, 3)。\\n    cam_pose (ndarray): 相机位姿（即外参），形状为 (4, 4)。\\n    obs_weight (float): 当前观测的权重。较高的值表示较高的权重。\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "将一个深度图像帧集成到 TSDF 体积中。\n",
    "\n",
    "参数:\n",
    "    depth_im (ndarray): 深度图像，形状为 (H, W)。\n",
    "    cam_intr (ndarray): 相机内参矩阵，形状为 (3, 3)。\n",
    "    cam_pose (ndarray): 相机位姿（即外参），形状为 (4, 4)。\n",
    "    obs_weight (float): 当前观测的权重。较高的值表示较高的权重。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一部分：对于每个体素，将它的体素坐标和深度图的像素一一对应，并筛选本次要更新的体素\n",
    "1. 对于每个体素，将它的体素坐标转化为世界坐标\n",
    "2. 将体素的世界坐标转化为相机坐标系下的坐标\n",
    "3. 通过相机坐标计算出体素在深度图上的投影像素点\n",
    "4. 删去那些在深度图平面上的投影不在深度图范围内的体素\n",
    "5. 计算剩余体素的深度（到光心的距离），在剩下的体素中筛选出深度小于或约等于对应深度图像素深度的体素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cam_pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mvox2world(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvol_origin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvox_coords, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_size) \u001b[38;5;66;03m# 将体素网格坐标转换为世界坐标\u001b[39;00m\n\u001b[0;32m      3\u001b[0m cam_pts \u001b[38;5;241m=\u001b[39m rigid_transform(cam_pts, np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(cam_pose))  \u001b[38;5;66;03m# 将点从世界坐标系转换到相机坐标系\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pix_z \u001b[38;5;241m=\u001b[39m cam_pts[:, \u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# 提取 z 坐标\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "cam_pts = self.vox2world(self.vol_origin, self.vox_coords, self.voxel_size) # 将体素网格坐标转换为世界坐标\n",
    "\n",
    "cam_pts = rigid_transform(cam_pts, np.linalg.inv(cam_pose))  # 将点从世界坐标系转换到相机坐标系\n",
    "\n",
    "pix_z = cam_pts[:, 2]  # 提取 z 坐标\n",
    "pix = self.cam2pix(cam_pts, cam_intr)  # 将相机坐标系下的点投影到像素坐标系\n",
    "pix_x, pix_y = pix[:, 0], pix[:, 1]  # 分别提取 x 和 y 像素坐标\n",
    "im_h, im_w = depth_im.shape  # 获取深度图像的高度和宽度\n",
    "# 剔除视锥体外的像素\n",
    "valid_pix = np.logical_and(pix_x >= 0,\n",
    "            np.logical_and(pix_x < im_w,\n",
    "            np.logical_and(pix_y >= 0,\n",
    "            np.logical_and(pix_y < im_h,\n",
    "                            pix_z > 0))))\n",
    "\n",
    "depth_val = np.zeros(pix_x.shape)  # 初始化深度值数组\n",
    "# 布尔数组在索引位置，用于指示哪些像素位置是有效的\n",
    "depth_val[valid_pix] = depth_im[pix_y[valid_pix], pix_x[valid_pix]]  # 获取有效像素的深度值\n",
    "\n",
    "depth_diff = depth_val - pix_z  # 计算深度差 depth_val: 图像中像素的深度信息，pix_z: 点的深度信息\n",
    "\n",
    "valid_pts = np.logical_and(depth_val > 0, depth_diff >= -self.trunc_margin)  # 筛选出有效点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二部分：对于筛选出的体素，用它们更新体素网格对象的tsdf矩阵\n",
    "1. 用体素到光心的距离进行截断，计算它们的tsdf值\n",
    "2. 将他们的权重设为1\n",
    "3. 获取待更新体素的旧tsdf值和权重值\n",
    "4. 融合旧tsdf生成体素的新tsdf值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.minimum(1, depth_diff / self.trunc_margin)  # 计算 TSDF 距离值\n",
    "    \n",
    "valid_vox_x = self.vox_coords[valid_pts, 0]  # 获取有效体素的 x 坐标\n",
    "valid_vox_y = self.vox_coords[valid_pts, 1]  # 获取有效体素的 y 坐标\n",
    "valid_vox_z = self.vox_coords[valid_pts, 2]  # 获取有效体素的 z 坐标\n",
    "    \n",
    "w_old = self.weightvol[valid_vox_x, valid_vox_y, valid_vox_z]  # 获取旧的权重值\n",
    "    \n",
    "tsdf_vals = self.tsdfvol[valid_vox_x, valid_vox_y, valid_vox_z]  # 获取旧的 TSDF 值\n",
    "    \n",
    "valid_dist = dist[valid_pts]  # 获取有效的 TSDF 距离值\n",
    "\n",
    "tsdfvol_new, w_new = self.integratetsdf(tsdf_vals, valid_dist, w_old, obs_weight)  # 计算新的 TSDF 值和权重\n",
    "\n",
    "self.weightvol[valid_vox_x, valid_vox_y, valid_vox_z] = w_new  # 更新权重值\n",
    "\n",
    "self.tsdfvol[valid_vox_x, valid_vox_y, valid_vox_z] = tsdfvol_new  # 更新 TSDF 值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. ICP算法实现\n",
    "- `icp/icp.py`文件下的函数`icp`对算法进行了实现\n",
    "- ICP（Iterative Closest Point）算法是一种常用的点云配准方法，用于将两个点云对齐，使得它们的重叠部分尽可能匹配\n",
    "- ICP算法使用迭代法，通过不断寻找最近点配对并计算旋转矩阵和平移向量的方式获取两个点云之间最终的旋转矩阵和平移向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp(source_points, target_points, max_iterations=10, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    实现ICP算法以对齐source_points到target_points，并记录每次迭代的点云变换。\n",
    "\n",
    "    参数:\n",
    "    source_points (numpy.ndarray): 需要对齐的源点云\n",
    "    target_points (numpy.ndarray): 目标点云\n",
    "    max_iterations (int): 最大迭代次数\n",
    "    tolerance (float): 迭代停止的误差阈值\n",
    "\n",
    "    返回:\n",
    "    R (numpy.ndarray): 旋转矩阵\n",
    "    T (numpy.ndarray): 平移向量\n",
    "    tran_points_list (list): 每次迭代后的变换点云列表\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对ICP算法的一次迭代进行讲解\n",
    "#### 名词\n",
    "- 初始点云和最终点云：icp算法的参数，算法需要计算初始点云通过刚性变换转移到最终点云的旋转和平移矩阵\n",
    "- 当前点云和目标点云：icp一次迭代过程中的变量，在一次迭代中需要算出当前点云通过刚性变换转移到目标点云的旋转和平移矩阵\n",
    "- 最终的旋转和平移矩阵相当于每次迭代进行的旋转和平移的累计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一部分，获取目标点云\n",
    "1. 得到上一次迭代之后的旋转平移矩阵，作用于初始点云从而得到当前点云（前一次迭代的结果）\n",
    "2. 对当前点云中的每个点，查找它在最终点云中距离最近的点（使用八叉树优化查询），并将结果保存为此次迭代的目标点云\n",
    "3. 计算和目标点云的平均距离，如满足匹配误差则返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将源点云应用当前的旋转和平移变换\n",
    "pre_points = np.dot(source_points, R.T) + T\n",
    "tran_points_list.append(pre_points)\n",
    "\n",
    "# 查找变换后的点云中每个点的最近邻目标点\n",
    "dis, idx = target_kdtree.query(pre_points)\n",
    "print(dis.shape, idx.shape)\n",
    "fut_points = target_points[idx] # 未来的目标点云\n",
    "\n",
    "# 计算误差（变换后点到目标点的平均距离）\n",
    "error = np.mean(dis)\n",
    "# 如果误差小于阈值，停止迭代\n",
    "if error < tolerance:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二部分，计算当前点云到目标点云的旋转平移矩阵\n",
    "1. 计算当前点云和目标点云的质心，并将他们都转化到质心坐标系\n",
    "2. 计算两个质心都在原点的点云之间的旋转矩阵（奇异值分解法）\n",
    "3. 计算出旋转矩阵后推导出平移向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算源点和目标点的质心\n",
    "centroid_source = np.mean(pre_points, axis=0)\n",
    "centroid_target = np.mean(fut_points, axis=0)\n",
    "\n",
    "# 将点云转换到质心坐标系\n",
    "source_centered = pre_points - centroid_source\n",
    "target_centered = fut_points - centroid_target\n",
    "\n",
    "# 计算相关矩阵H\n",
    "H = np.dot(source_centered.T, target_centered)\n",
    "# 通过奇异值分解（SVD）计算最佳旋转矩阵\n",
    "U, S, Vt = np.linalg.svd(H)\n",
    "R_iter = np.dot(Vt.T, U.T)\n",
    "\n",
    "# 确保旋转矩阵的正定性\n",
    "if np.linalg.det(R_iter) < 0:\n",
    "    Vt[2, :] *= -1\n",
    "    R_iter = np.dot(Vt.T, U.T)\n",
    "\n",
    "# 计算最佳平移向量\n",
    "T_iter = centroid_target - np.dot(centroid_source, R_iter.T)\n",
    "\n",
    "# 更新总的旋转矩阵和平移向量\n",
    "R = np.dot(R_iter, R)\n",
    "T = np.dot(R_iter, T) + T_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICP算法正确性证明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设 $\\mathbf{x}_i, \\mathbf{y}_i$ 分别为当前点云和目标点云在质心坐标系下的三维坐标向量\n",
    "\n",
    "令 $ \\mathbf{R}^* = \\arg \\min_{\\mathbf{R}} \\sum_{i=1}^{n} \\| \\mathbf{x}_i - \\mathbf{R} \\mathbf{y}_i \\|^2 $，我们可以将目标函数展开并进行简化：\n",
    "\n",
    "$$\n",
    "\\mathbf{R}^* = \\arg \\min_{\\mathbf{R}} \\sum_{i=1}^{n} \\| \\mathbf{x}_i - \\mathbf{R} \\mathbf{y}_i \\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\arg \\min_{\\mathbf{R}} \\sum_{i=1}^{n} (\\mathbf{x}_i - \\mathbf{R} \\mathbf{y}_i)^T (\\mathbf{x}_i - \\mathbf{R} \\mathbf{y}_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\arg \\min_{\\mathbf{R}} \\sum_{i=1}^{n} (\\mathbf{x}_i^T \\mathbf{x}_i - \\mathbf{x}_i^T \\mathbf{R} \\mathbf{y}_i - \\mathbf{y}_i^T \\mathbf{R}^T \\mathbf{x}_i + \\mathbf{y}_i^T \\mathbf{R}^T \\mathbf{R} \\mathbf{y}_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\arg \\min_{\\mathbf{R}} \\sum_{i=1}^{n} (\\mathbf{x}_i^T \\mathbf{x}_i - 2 \\mathbf{x}_i^T \\mathbf{R} \\mathbf{y}_i + \\mathbf{y}_i^T \\mathbf{y}_i)\n",
    "$$\n",
    "\n",
    "由于 $\\mathbf{x}_i^T \\mathbf{x}_i$ 和 $\\mathbf{y}_i^T \\mathbf{y}_i$ 是常数，可以忽略，因此目标函数转化为：\n",
    "\n",
    "$$\n",
    "\\mathbf{R}^* = \\arg \\max_{\\mathbf{R}} \\sum_{i=1}^{n} \\mathbf{x}_i^T \\mathbf{R} \\mathbf{y}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\arg \\max_{\\mathbf{R}} \\text{tr} \\left( \\sum_{i=1}^{n} \\mathbf{x}_i^T \\mathbf{R} \\mathbf{y}_i \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\arg \\max_{\\mathbf{R}} \\text{tr} \\left( \\mathbf{R} \\sum_{i=1}^{n} \\mathbf{y}_i \\mathbf{x}_i^T \\right)\n",
    "$$\n",
    "\n",
    "令 $\\mathbf{S} = \\sum_{i=1}^{n} \\mathbf{y}_i \\mathbf{x}_i^T$，则：\n",
    "\n",
    "$$\n",
    "\\mathbf{R}^* = \\arg \\max_{\\mathbf{R}} \\text{tr} (\\mathbf{R} \\mathbf{S})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "记 $ \\boldsymbol{H} = \\sum_{i=1}^{n} \\boldsymbol{y}_i \\boldsymbol{x}_i^\\mathrm{T} $，有：\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{R}} = \\arg \\max_{\\boldsymbol{R}} \\operatorname{tr} \\left( \\boldsymbol{R} \\boldsymbol{H} \\right)\n",
    "$$\n",
    "\n",
    "现在对 $ \\boldsymbol{H} $ 进行SVD分解可得：\n",
    "\n",
    "$$\n",
    "\\boldsymbol{H} = \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^\\mathrm{T}\n",
    "$$\n",
    "\n",
    "则：\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{R}} = \\arg \\max_{\\boldsymbol{R}} \\operatorname{tr} \\left( \\boldsymbol{R} \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^\\mathrm{T} \\right) = \\arg \\max_{\\boldsymbol{R}} \\operatorname{tr} \\left( \\boldsymbol{\\Sigma} \\boldsymbol{V}^\\mathrm{T} \\boldsymbol{R} \\boldsymbol{U} \\right)\n",
    "$$\n",
    "\n",
    "记 $ \\boldsymbol{M} = \\boldsymbol{V}^\\mathrm{T} \\boldsymbol{R} \\boldsymbol{U} $，又 $ \\boldsymbol{\\Sigma} $ 是对角阵，那么：\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{R}} = \\arg \\max_{\\boldsymbol{R}} \\operatorname{tr} \\left( \\boldsymbol{\\Sigma} \\boldsymbol{M} \\right) = \\arg \\max_{\\boldsymbol{R}} \\operatorname{tr} \\left( \\sum_{i=1}^{n} \\sigma_i m_{ii} \\right)\n",
    "$$\n",
    "\n",
    "因为 $ \\boldsymbol{V}^\\mathrm{T} $, $ \\boldsymbol{R} $, $ \\boldsymbol{U} $ 均为正交矩阵，所以 $ \\boldsymbol{M} $ 是正交矩阵，则 $ m_{ij} \\leq 1 $。\n",
    "\n",
    "故当 $ m_{ii} = 1 $ 时， $ \\sum_{i=1}^{n} \\sigma_i m_{ii} $ 取到最大值。\n",
    "\n",
    "而 $ \\boldsymbol{M} $ 是正交矩阵，所以：\n",
    "\n",
    "$$\n",
    "\\boldsymbol{M} = \\boldsymbol{I}\n",
    "$$\n",
    "\n",
    "即\n",
    "\n",
    "$$\n",
    "\\boldsymbol{V}^\\mathrm{T} \\boldsymbol{R} \\boldsymbol{U} = \\boldsymbol{I}\n",
    "$$\n",
    "\n",
    "所以\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{R}} = \\boldsymbol{V} \\boldsymbol{U}^\\mathrm{T}\n",
    "$$\n",
    "\n",
    "至此，求得最优的 $ \\boldsymbol{R} $ 与 $ \\boldsymbol{t} $。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
