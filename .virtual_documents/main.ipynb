





!tree -I "myenv|stair|*.jpg|*.txt|*.png|*.pyc|__*"





# numba示例代码
from numba import njit, prange
import numpy as np

@njit(parallel=True)
def parallel_sum(arr):
    total = 0.0
    for i in prange(arr.shape[0]):
        total += arr[i]
    return total

# 示例数据
data = np.ones(100000000)

# 调用并输出结果
result = parallel_sum(data)
print("Sum:", result)








def vox2world(vol_origin, vox_coords, vox_size):
    # 将体素网格坐标转换为世界坐标。
    vol_origin = vol_origin.astype(np.float32)
    vox_coords = vox_coords.astype(np.float32)
    cam_pts = np.empty_like(vox_coords, dtype=np.float32)

    # 使用并行循环将每个体素网格坐标转换为世界坐标
    for i in prange(vox_coords.shape[0]):
        for j in range(3):
            cam_pts[i, j] = vol_origin[j] + (vox_size * vox_coords[i, j])
    return cam_pts





def cam2pix(cam_pts, intr):
    # 将相机坐标转换为像素坐标。
    intr = intr.astype(np.float32)
    fx, fy = intr[0, 0], intr[1, 1]
    cx, cy = intr[0, 2], intr[1, 2]
    pix = np.empty((cam_pts.shape[0], 2), dtype=np.int64)
    for i in prange(cam_pts.shape[0]):
        pix[i, 0] = int(np.round((cam_pts[i, 0] * fx / cam_pts[i, 2]) + cx))
        pix[i, 1] = int(np.round((cam_pts[i, 1] * fy / cam_pts[i, 2]) + cy))
    return pix

cam_pts = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
intr = np.array([[100, 0, 200], [0, 100, 300], [0, 0, 1]])
cam2pix(cam_pts, intr)





def integratetsdf(tsdfvol, dist, w_old, obs_weight):
    # 融合TSDF值
    tsdfvol_int = np.empty_like(tsdfvol, dtype=np.float32)
    w_new = np.empty_like(w_old, dtype=np.float32)
    for i in prange(len(tsdfvol)):
        w_new[i] = w_old[i] + obs_weight
        tsdfvol_int[i] = (w_old[i] * tsdfvol[i] + obs_weight * dist[i]) / w_new[i]
    return tsdfvol_int, w_new

tsdfvol = np.array([0.1, 0.2, 0.3])
dist = np.array([1.0, 2.0, 3.0])
w_old = np.array([1.0,2.0,3.0])
obs_weight = 1.0
integratetsdf(tsdfvol, dist, w_old, obs_weight)





"""
将一个深度图像帧集成到 TSDF 体积中。

参数:
    depth_im (ndarray): 深度图像，形状为 (H, W)。
    cam_intr (ndarray): 相机内参矩阵，形状为 (3, 3)。
    cam_pose (ndarray): 相机位姿（即外参），形状为 (4, 4)。
    obs_weight (float): 当前观测的权重。较高的值表示较高的权重。
"""





cam_pts = self.vox2world(self.vol_origin, self.vox_coords, self.voxel_size) # 将体素网格坐标转换为世界坐标

cam_pts = rigid_transform(cam_pts, np.linalg.inv(cam_pose))  # 将点从世界坐标系转换到相机坐标系

pix_z = cam_pts[:, 2]  # 提取 z 坐标
pix = self.cam2pix(cam_pts, cam_intr)  # 将相机坐标系下的点投影到像素坐标系
pix_x, pix_y = pix[:, 0], pix[:, 1]  # 分别提取 x 和 y 像素坐标
im_h, im_w = depth_im.shape  # 获取深度图像的高度和宽度
# 剔除视锥体外的像素
valid_pix = np.logical_and(pix_x >= 0,
            np.logical_and(pix_x < im_w,
            np.logical_and(pix_y >= 0,
            np.logical_and(pix_y < im_h,
                            pix_z > 0))))

depth_val = np.zeros(pix_x.shape)  # 初始化深度值数组
# 布尔数组在索引位置，用于指示哪些像素位置是有效的
depth_val[valid_pix] = depth_im[pix_y[valid_pix], pix_x[valid_pix]]  # 获取有效像素的深度值

depth_diff = depth_val - pix_z  # 计算深度差 depth_val: 图像中像素的深度信息，pix_z: 点的深度信息

valid_pts = np.logical_and(depth_val > 0, depth_diff >= -self.trunc_margin)  # 筛选出有效点





dist = np.minimum(1, depth_diff / self.trunc_margin)  # 计算 TSDF 距离值
    
valid_vox_x = self.vox_coords[valid_pts, 0]  # 获取有效体素的 x 坐标
valid_vox_y = self.vox_coords[valid_pts, 1]  # 获取有效体素的 y 坐标
valid_vox_z = self.vox_coords[valid_pts, 2]  # 获取有效体素的 z 坐标
    
w_old = self.weightvol[valid_vox_x, valid_vox_y, valid_vox_z]  # 获取旧的权重值
    
tsdf_vals = self.tsdfvol[valid_vox_x, valid_vox_y, valid_vox_z]  # 获取旧的 TSDF 值
    
valid_dist = dist[valid_pts]  # 获取有效的 TSDF 距离值

tsdfvol_new, w_new = self.integratetsdf(tsdf_vals, valid_dist, w_old, obs_weight)  # 计算新的 TSDF 值和权重

self.weightvol[valid_vox_x, valid_vox_y, valid_vox_z] = w_new  # 更新权重值

self.tsdfvol[valid_vox_x, valid_vox_y, valid_vox_z] = tsdfvol_new  # 更新 TSDF 值





def icp(source_points, target_points, max_iterations=10, tolerance=1e-6):
    """
    实现ICP算法以对齐source_points到target_points，并记录每次迭代的点云变换。

    参数:
    source_points (numpy.ndarray): 需要对齐的源点云
    target_points (numpy.ndarray): 目标点云
    max_iterations (int): 最大迭代次数
    tolerance (float): 迭代停止的误差阈值

    返回:
    R (numpy.ndarray): 旋转矩阵
    T (numpy.ndarray): 平移向量
    tran_points_list (list): 每次迭代后的变换点云列表
    """








# 将源点云应用当前的旋转和平移变换
pre_points = np.dot(source_points, R.T) + T
tran_points_list.append(pre_points)

# 查找变换后的点云中每个点的最近邻目标点
dis, idx = target_kdtree.query(pre_points)
print(dis.shape, idx.shape)
fut_points = target_points[idx] # 未来的目标点云

# 计算误差（变换后点到目标点的平均距离）
error = np.mean(dis)
# 如果误差小于阈值，停止迭代
if error < tolerance:
    exit()





# 计算源点和目标点的质心
centroid_source = np.mean(pre_points, axis=0)
centroid_target = np.mean(fut_points, axis=0)

# 将点云转换到质心坐标系
source_centered = pre_points - centroid_source
target_centered = fut_points - centroid_target

# 计算相关矩阵H
H = np.dot(source_centered.T, target_centered)
# 通过奇异值分解（SVD）计算最佳旋转矩阵
U, S, Vt = np.linalg.svd(H)
R_iter = np.dot(Vt.T, U.T)

# 确保旋转矩阵的正定性
if np.linalg.det(R_iter) < 0:
    Vt[2, :] *= -1
    R_iter = np.dot(Vt.T, U.T)

# 计算最佳平移向量
T_iter = centroid_target - np.dot(centroid_source, R_iter.T)

# 更新总的旋转矩阵和平移向量
R = np.dot(R_iter, R)
T = np.dot(R_iter, T) + T_iter









